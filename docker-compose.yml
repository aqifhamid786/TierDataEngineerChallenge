version: "3"
services:
    
    # Data broker. 
    zookeeper:
        image: wurstmeister/zookeeper
        container_name: zookeeper
        restart: always
        ports:
            - "2181:2181"
    kafka:
        image: wurstmeister/kafka
        container_name: kafka
        restart: always
        depends_on:
            - zookeeper
        ports:
            - "9092:9092"
        environment:
            KAFKA_ADVERTISED_HOST_NAME: kafka
            KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
            KAFKA_CREATE_TOPICS: "weather:1:1,track_events:1:1"
            
    # Pipeline sink. 
    mysql:
        image: mysql
        container_name: mysql
        restart: always
        environment:
            MYSQL_DATABASE: "tier_warehouse"
            MYSQL_USER: "user"
            MYSQL_PASSWORD: "user"
            MYSQL_ROOT_PASSWORD: "root"
        ports:
            - "3306:3306"
        expose:
            - "3306"
        volumes:
            - ./volumes/mysql:/var/lib/mysql
            
    # Spark cluster services 
    spark-master:
        image: docker.io/bitnami/spark:3.1.1
        container_name: spark-master
        user: root
        environment:
            - SPARK_MODE=master
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
        ports:
            - '8080:8080'
        volumes:
            - ./volumes/spark_app:/opt/bitnami/app/builds

    spark-worker-1:
        image: docker.io/bitnami/spark:3.1.1
        container_name: spark-worker-1
        user: root
        depends_on: 
            - spark-master
            - kafka
            - mysql
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
        ports:
            - '8081:8081'
        volumes:
            - ./volumes/spark_app:/opt/bitnami/app/builds
            - ./volumes/spark_jars:/opt/bitnami/spark/ivy:z

    spark-worker-2:
        image: docker.io/bitnami/spark:3.1.1
        container_name: spark-worker-2
        user: root
        depends_on: 
            - spark-master
            - kafka
            - mysql
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark-master:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
        ports:
            - '8082:8081'
        volumes:
            - ./volumes/spark_app:/opt/bitnami/app/builds
            - ./volumes/spark_jars:/opt/bitnami/spark/ivy:z

    # Our data producer.
    producer-kafka:
        build: ./KafkaProducer
        container_name: kafka-producer
        user: root
        environment:
            - PRODUCER_MAIN_CLASS=com.aqif.tier.challenge.kafka.KafkaProducer
            - PRODUCER_JAR=KafkaProducer-1.0-SNAPSHOT-jar-with-dependencies.jar
        depends_on: 
            - spark-worker-1
            - spark-worker-2

    # Our ETL pipeline for weather data source.  
    etl-pipeline-weather:
        build: ./ETLPipeline
        container_name: etl-pipeline-weather
        user: root
        environment: 
            - ETL_PIPELINE=WEATHER
            - SPARK_MASTER_URL=spark://spark-master:7077
            - SPARK_JOB_DEPENDENCIES=org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1,mysql:mysql-connector-java:8.0.25
            - SPARK_JOB_MAIN_CLASS=com.aqif.tier.challenge.spark.TierETLJobRunner
            - SPARK_JOB_JAR=ETLPipeline-1.0-SNAPSHOT.jar
            - SPARK_JOB_MAX_MEMORY=512M
            - SPARK_JOB_MAX_CORES=1
        ports:
            - "4040:4040"
            - "4043:4043"
            - "5000-5010:5000-5010"
        depends_on: 
            - mysql
            - spark-worker-1
            - spark-worker-2
        volumes:
            - ./volumes/spark_jars/2:/opt/bitnami/spark/ivy:z
    
    # Our ETL pipeline for segment-track data source. 
    etl-pipeline-segment-track:
        build: ./ETLPipeline
        container_name: etl-pipeline-segment-track
        user: root
        environment: 
            - ETL_PIPELINE=SEGMENT_TRACK
            - SPARK_MASTER_URL=spark://spark-master:7077
            - SPARK_JOB_DEPENDENCIES=org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1,mysql:mysql-connector-java:8.0.25
            - SPARK_JOB_MAIN_CLASS=com.aqif.tier.challenge.spark.TierETLJobRunner
            - SPARK_JOB_JAR=ETLPipeline-1.0-SNAPSHOT.jar
            - SPARK_JOB_MAX_MEMORY=512M
            - SPARK_JOB_MAX_CORES=1
        ports:
            - "4041:4040"
            - "4044:4043"
            - "5020-5030:5000-5010"
        depends_on: 
            - mysql
            - spark-worker-1
            - spark-worker-2
        volumes:
            - ./volumes/spark_jars/1:/opt/bitnami/spark/ivy:z